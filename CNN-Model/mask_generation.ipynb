{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879162c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdf57ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import cv2  # For saving masks (optional)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe13700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the HDF5 file\n",
    "def load_h5_data(file_path, target_layers=['ILM', 'PR1', 'BM'], num_samples=3):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Load only the first num_samples images\n",
    "        images = f['images'][:num_samples]  # Shape: (num_samples, height, width)\n",
    "        layer_group = f['layers']\n",
    "        \n",
    "        # Filter only the target layers we want\n",
    "        layers = {}\n",
    "        for layer_name in target_layers:\n",
    "            if layer_name in layer_group:\n",
    "                layers[layer_name] = layer_group[layer_name][:num_samples]  # Shape: (num_samples, 768)\n",
    "            else:\n",
    "                print(f\"Warning: Layer '{layer_name}' not found in the data\")\n",
    "        \n",
    "        layer_names = list(layers.keys())\n",
    "    return images, layers, layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bdf503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (3, 496, 768)\n",
      "Layer 'ILM' shape: (3, 768)\n",
      "Layer 'PR1' shape: (3, 768)\n",
      "Layer 'BM' shape: (3, 768)\n"
     ]
    }
   ],
   "source": [
    "images, layers, layer_names = load_h5_data('/home/suraj/Git/SCR-Progression/e2e/Nemours_Jing_RL_Annotated.h5')\n",
    "#image and layer shapes\n",
    "print(f\"Image shape: {images.shape}\")\n",
    "for layer_name, layer_data in layers.items():\n",
    "    print(f\"Layer '{layer_name}' shape: {layer_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2843c6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate segmentation masks - Corrected Layer Ordering\n",
    "def generate_masks(images, layers, layer_names, height=None, width=768):\n",
    "    if height is None:\n",
    "        height = images.shape[1]  # Get height from actual image dimensions\n",
    "        \n",
    "    batch_size = images.shape[0]\n",
    "    \n",
    "    # Initialize segmentation masks: batch_size x height x width\n",
    "    # Class 0: Background, Class 1: ILM to BM, Class 2: BM to PR1\n",
    "    segmentation_masks = np.zeros((batch_size, height, width), dtype=np.uint8)\n",
    "    \n",
    "    print(f\"Creating masks for {batch_size} images of size {height}x{width}\")\n",
    "    print(\"Layer order (top to bottom): ILM -> BM -> PR1\")\n",
    "    \n",
    "    # Process each image in the batch\n",
    "    for b in range(batch_size):\n",
    "        print(f\"Processing image {b+1}/{batch_size}\")\n",
    "        \n",
    "        # Get the layer boundaries for this image\n",
    "        ilm_line = layers['ILM'][b]      # Shape: (768,) - y-coordinates for each x (topmost)\n",
    "        bm_line = layers['BM'][b]        # Shape: (768,) - y-coordinates for each x (middle)\n",
    "        pr1_line = layers['PR1'][b]      # Shape: (768,) - y-coordinates for each x (bottommost)\n",
    "        \n",
    "        # Process each column (x-coordinate)\n",
    "        for x in range(width):\n",
    "            # Get y-coordinates for the three layers at this x position\n",
    "            ilm_y = ilm_line[x]    # Topmost layer\n",
    "            bm_y = bm_line[x]      # Middle layer  \n",
    "            pr1_y = pr1_line[x]    # Bottommost layer\n",
    "            \n",
    "            # Skip if any layer has NaN (no annotation in this region)\n",
    "            if np.isnan(ilm_y) or np.isnan(bm_y) or np.isnan(pr1_y):\n",
    "                continue\n",
    "                \n",
    "            # Convert to integer pixel coordinates\n",
    "            ilm_y = int(round(ilm_y))\n",
    "            bm_y = int(round(bm_y))\n",
    "            pr1_y = int(round(pr1_y))\n",
    "            \n",
    "            # Ensure coordinates are within image bounds\n",
    "            ilm_y = max(0, min(ilm_y, height-1))\n",
    "            bm_y = max(0, min(bm_y, height-1))\n",
    "            pr1_y = max(0, min(pr1_y, height-1))\n",
    "            \n",
    "            # Ensure proper ordering: ILM (top) < BM (middle) < PR1 (bottom)\n",
    "            # Sort the three points to ensure correct ordering\n",
    "            layer_points = sorted([ilm_y, bm_y, pr1_y])\n",
    "            top_y, mid_y, bottom_y = layer_points\n",
    "            \n",
    "            # Fill the regions:\n",
    "            # Region 1: From top layer to middle layer (Class 1) - ILM to BM region\n",
    "            if top_y < mid_y:\n",
    "                segmentation_masks[b, top_y:mid_y, x] = 1\n",
    "                \n",
    "            # Region 2: From middle layer to bottom layer (Class 2) - BM to PR1 region\n",
    "            if mid_y < bottom_y:\n",
    "                segmentation_masks[b, mid_y:bottom_y, x] = 2\n",
    "                \n",
    "            # Everything else remains Class 0 (background)\n",
    "        \n",
    "        # Print some statistics for this image\n",
    "        unique_classes = np.unique(segmentation_masks[b])\n",
    "        class_counts = [(cls, np.sum(segmentation_masks[b] == cls)) for cls in unique_classes]\n",
    "        print(f\"  Image {b+1} - Classes and pixel counts: {class_counts}\")\n",
    "    \n",
    "    return segmentation_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e4a9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Post-process masks (optional)\n",
    "def smooth_masks(masks, kernel_size=3):\n",
    "    smoothed_masks = masks.copy()\n",
    "    kernel = np.ones((kernel_size, kernel_size), np.uint8)\n",
    "    for b in range(masks.shape[0]):\n",
    "        smoothed_masks[b] = cv2.morphologyEx(masks[b], cv2.MORPH_CLOSE, kernel)\n",
    "    return smoothed_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11818fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save or visualize masks\n",
    "def save_masks(multiclass_masks, output_dir='masks'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving {multiclass_masks.shape[0]} sample masks to {output_dir}/\")\n",
    "    \n",
    "    for b in range(multiclass_masks.shape[0]):\n",
    "        # Save multi-class mask (scale values for better visibility)\n",
    "        multiclass_filename = f'{output_dir}/segmentation_mask_sample_{b}.png'\n",
    "        cv2.imwrite(multiclass_filename, multiclass_masks[b] * 85)  # Scale 0,1,2 -> 0,85,170 for visibility\n",
    "    \n",
    "    print(\"Segmentation mask classes (corrected layer order):\")\n",
    "    print(\"  Class 0: Background\")\n",
    "    print(\"  Class 1: ILM to BM region (upper retinal layers)\") \n",
    "    print(\"  Class 2: BM to PR1 region (photoreceptor region)\")\n",
    "    print(f\"Unique values in masks: {np.unique(multiclass_masks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01600465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function\n",
    "def main(h5_file_path):\n",
    "    print(f\"Loading data from: {h5_file_path}\")\n",
    "    \n",
    "    # Load data (only 3 samples, only ILM, PR1, BM layers)\n",
    "    images, layers, layer_names = load_h5_data(h5_file_path)\n",
    "    \n",
    "    print(f\"Loaded {images.shape[0]} images with shape {images.shape}\")\n",
    "    print(f\"Processing layers: {layer_names}\")\n",
    "    \n",
    "    # Generate masks\n",
    "    multiclass_masks = generate_masks(images, layers, layer_names)\n",
    "    \n",
    "    print(f\"Generated segmentation masks with shape: {multiclass_masks.shape}\")\n",
    "    \n",
    "    # Optional: Smooth masks to reduce noise\n",
    "    multiclass_masks = smooth_masks(multiclass_masks)\n",
    "    \n",
    "    # Save masks\n",
    "    save_masks(multiclass_masks)\n",
    "    \n",
    "    return multiclass_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de296c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/suraj/Git/SCR-Progression/e2e/Nemours_Jing_RL_Annotated.h5\n",
      "Loaded 3 images with shape (3, 496, 768)\n",
      "Processing layers: ['ILM', 'PR1', 'BM']\n",
      "Creating masks for 3 images of size 496x768\n",
      "Layer order (top to bottom): ILM -> BM -> PR1\n",
      "Processing image 1/3\n",
      "  Image 1 - Classes and pixel counts: [(0, 286587), (1, 31342), (2, 62999)]\n",
      "Processing image 2/3\n",
      "  Image 2 - Classes and pixel counts: [(0, 286470), (1, 31481), (2, 62977)]\n",
      "Processing image 3/3\n",
      "  Image 3 - Classes and pixel counts: [(0, 286502), (1, 31424), (2, 63002)]\n",
      "Generated segmentation masks with shape: (3, 496, 768)\n",
      "Saving 3 sample masks to masks/\n",
      "Segmentation mask classes (corrected layer order):\n",
      "  Class 0: Background\n",
      "  Class 1: ILM to BM region (upper retinal layers)\n",
      "  Class 2: BM to PR1 region (photoreceptor region)\n",
      "Unique values in masks: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    h5_file_path = '/home/suraj/Git/SCR-Progression/e2e/Nemours_Jing_RL_Annotated.h5'\n",
    "    multiclass_masks = main(h5_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e3b6c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing corrected mask generation...\n",
      "Creating masks for 3 images of size 496x768\n",
      "Layer order (top to bottom): ILM -> BM -> PR1\n",
      "Processing image 1/3\n",
      "  Image 1 - Classes and pixel counts: [(0, 286587), (1, 31342), (2, 62999)]\n",
      "Processing image 2/3\n",
      "  Image 2 - Classes and pixel counts: [(0, 286470), (1, 31481), (2, 62977)]\n",
      "Processing image 3/3\n",
      "  Image 3 - Classes and pixel counts: [(0, 286502), (1, 31424), (2, 63002)]\n",
      "\n",
      "Corrected mask shape: (3, 496, 768)\n",
      "Unique values across all masks: [0 1 2]\n",
      "Image 1:\n",
      "  Class 0 (Background): 286587 pixels (75.2%)\n",
      "  Class 1 (ILM-to-BM): 31342 pixels (8.2%)\n",
      "  Class 2 (BM-to-PR1): 62999 pixels (16.5%)\n",
      "Image 2:\n",
      "  Class 0 (Background): 286470 pixels (75.2%)\n",
      "  Class 1 (ILM-to-BM): 31481 pixels (8.3%)\n",
      "  Class 2 (BM-to-PR1): 62977 pixels (16.5%)\n",
      "Image 3:\n",
      "  Class 0 (Background): 286502 pixels (75.2%)\n",
      "  Class 1 (ILM-to-BM): 31424 pixels (8.2%)\n",
      "  Class 2 (BM-to-PR1): 63002 pixels (16.5%)\n",
      "Saving 3 sample masks to masks/\n",
      "Segmentation mask classes (corrected layer order):\n",
      "  Class 0: Background\n",
      "  Class 1: ILM to BM region (upper retinal layers)\n",
      "  Class 2: BM to PR1 region (photoreceptor region)\n",
      "Unique values in masks: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Test the corrected mask generation\n",
    "print(\"Testing corrected mask generation...\")\n",
    "\n",
    "# Generate masks with correct layer ordering\n",
    "corrected_masks = generate_masks(images, layers, layer_names)\n",
    "\n",
    "print(f\"\\nCorrected mask shape: {corrected_masks.shape}\")\n",
    "print(f\"Unique values across all masks: {np.unique(corrected_masks)}\")\n",
    "\n",
    "# Check each image individually\n",
    "for i in range(corrected_masks.shape[0]):\n",
    "    unique_vals, counts = np.unique(corrected_masks[i], return_counts=True)\n",
    "    total_pixels = corrected_masks[i].shape[0] * corrected_masks[i].shape[1]\n",
    "    percentages = (counts / total_pixels) * 100\n",
    "    print(f\"Image {i+1}:\")\n",
    "    for cls, count, pct in zip(unique_vals, counts, percentages):\n",
    "        region_name = [\"Background\", \"ILM-to-BM\", \"BM-to-PR1\"][cls]\n",
    "        print(f\"  Class {cls} ({region_name}): {count} pixels ({pct:.1f}%)\")\n",
    "\n",
    "# Save the corrected masks\n",
    "save_masks(corrected_masks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
